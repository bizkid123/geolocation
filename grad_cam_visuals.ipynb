{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWJ56CPHlM3FA9DxyyZSxD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fi\n",
        "!pip install timm"
      ],
      "metadata": {
        "id": "QeMbz9tqJCA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "8TgXO6PPJR_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-gradcam\n",
        "!pip install grad-cam"
      ],
      "metadata": {
        "id": "BYiyry8nJWV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unzip"
      ],
      "metadata": {
        "id": "6MJ2gCjRLUpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import fastai\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import wandb\n",
        "import fastai\n",
        "from fastai.vision.all import *\n",
        "from fastai.callback.wandb import WandbCallback\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "import PIL\n"
      ],
      "metadata": {
        "id": "72mpAAv_JGUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "K2BpoHneI_kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "GPy2d4hfLXK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq '/content/drive/My Drive/Geolocation/50States10K.zip' -d '/content/geolocation'"
      ],
      "metadata": {
        "id": "zON-QRpLLbhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = SimpleNamespace(\n",
        "    batch_size=32,\n",
        "    img_size=224,\n",
        "    seed=42,\n",
        "    pretrained=True,\n",
        "    normalize=True,\n",
        "    model_name=\"vit_small_patch32_224\",\n",
        "    epochs=20,  # FIX THIS LATER\n",
        "    learning_rate=2e-3,\n",
        "    resize=\"crop\",\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "zK1ma4IbMx3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def albumentations_transforms(x: PIL.Image.Image, img_size=224):\n",
        "    transforms = A.Compose(\n",
        "        [\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.ImageCompression(quality_lower=99, quality_upper=100),\n",
        "            A.ShiftScaleRotate(\n",
        "                shift_limit=0.2, scale_limit=0.2, rotate_limit=10, border_mode=0, p=0.7\n",
        "            ),\n",
        "            A.Resize(img_size, img_size),\n",
        "            A.Cutout(\n",
        "                max_h_size=int(img_size * 0.4),\n",
        "                max_w_size=int(img_size * 0.4),\n",
        "                num_holes=1,\n",
        "                p=0.5,\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return PIL.Image.fromarray(transforms(image=np.array(x))[\"image\"])\n",
        "\n",
        "def load_test_data(augment):\n",
        "    resize_method = (\n",
        "        ResizeMethod.Crop\n",
        "    )\n",
        "\n",
        "    if augment:\n",
        "        dls = fastai.vision.data.ImageDataLoaders.from_folder(\n",
        "            \"/content/geolocation/\",\n",
        "            valid_pct=0.99,\n",
        "            seed=config.seed,\n",
        "            bs=config.batch_size,\n",
        "            item_tfms=[\n",
        "                Resize(config.img_size, method=resize_method),\n",
        "                albumentations_transforms,\n",
        "            ],\n",
        "        )\n",
        "    else:\n",
        "        dls = fastai.vision.data.ImageDataLoaders.from_folder(\n",
        "            \"/content/geolocation/\",\n",
        "            valid_pct=0.99,\n",
        "            seed=config.seed,\n",
        "            bs=config.batch_size,\n",
        "            item_tfms=[Resize(config.img_size, method=resize_method)],\n",
        "        )\n",
        "\n",
        "    mean, std = (0.48145466, 0.4578275, 0.40821073), (\n",
        "        0.26862954,\n",
        "        0.26130258,\n",
        "        0.27577711,\n",
        "    )\n",
        "\n",
        "    if config.normalize:\n",
        "        dls.add_tfms([Normalize.from_stats(mean, std)], \"after_batch\")\n",
        "\n",
        "    return dls"
      ],
      "metadata": {
        "id": "tqmmKdtzMizR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from pytorch_grad_cam import GradCAM, \\\n",
        "    ScoreCAM, \\\n",
        "    GradCAMPlusPlus, \\\n",
        "    AblationCAM, \\\n",
        "    XGradCAM, \\\n",
        "    EigenCAM, \\\n",
        "    EigenGradCAM, \\\n",
        "    LayerCAM, \\\n",
        "    FullGrad, \\\n",
        "    DeepFeatureFactorization\n",
        "\n",
        "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image, \\\n",
        "    preprocess_image\n",
        "from pytorch_grad_cam.ablation_layer import AblationLayerVit"
      ],
      "metadata": {
        "id": "q5QlrbG3OWx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_learner(model_name, dls=None, augment=False, test_set=False):\n",
        "    if dls is None:\n",
        "        dls = load_test_data(augment)\n",
        "\n",
        "    learn = vision_learner(\n",
        "        dls,\n",
        "        model_name,\n",
        "        concat_pool=True,\n",
        "    ).to_fp16()\n",
        "\n",
        "    # To device\n",
        "    learn.dls.device = device\n",
        "\n",
        "    return learn\n",
        "  \n",
        "learn = create_learner(\"resnet18\", augment=False, test_set=True)"
      ],
      "metadata": {
        "id": "tF0nlcjdJBeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_wandb_model(model_num, learn):\n",
        "    run = wandb.init()\n",
        "    artifact = run.use_artifact(f\"ben_z/geolocation/model:v{model_num}\", type=\"model\")\n",
        "    artifact_dir = artifact.download()\n",
        "    file = torch.load(os.path.join(artifact_dir, \"model.pth\"), map_location=device)\n",
        "\n",
        "    # create a learner with vit_small_patch32_224\n",
        "    learn.model.load_state_dict(file)\n",
        "\n",
        "    # Move model to GPU\n",
        "    learn.model = learn.model.to(device)\n",
        "    learn.dls.device = device\n",
        "\n",
        "    return learn"
      ],
      "metadata": {
        "id": "XhSq2NHrNYJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()\n",
        "learn = load_wandb_model(15, learn)\n"
      ],
      "metadata": {
        "id": "bIDB1mA1Kd85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = learn.model[0].model\n",
        "model.eval"
      ],
      "metadata": {
        "id": "2ZeUc0EdPaxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from math import ceil, sqrt\n",
        "\n",
        "def display_grid_image(class_image_list):\n",
        "    # Calculate the grid size\n",
        "    num_images = len(class_image_list)\n",
        "    grid_size = ceil(sqrt(num_images))\n",
        "\n",
        "    # Set up the matplotlib figure\n",
        "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))\n",
        "    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
        "\n",
        "    # Flatten axes array if only 1 row or column\n",
        "    if grid_size == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    # Iterate through the class-image list and add them to the grid\n",
        "    for idx, (cls, img) in enumerate(class_image_list):\n",
        "        row, col = divmod(idx, grid_size)\n",
        "        ax = axes[row][col]\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(cls)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    # Remove unused subplots\n",
        "    for idx in range(num_images, grid_size * grid_size):\n",
        "        row, col = divmod(idx, grid_size)\n",
        "        fig.delaxes(axes[row][col])\n",
        "\n",
        "    # Show the grid\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "jRS0uXVtfRSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(path, state=None):\n",
        "  rgb_img = cv2.imread(path, 1)[:, :, ::-1]\n",
        "  rgb_img = cv2.resize(rgb_img, (224, 224))\n",
        "  rgb_img = np.float32(rgb_img) / 255\n",
        "  input_tensor = preprocess_image(rgb_img, mean=[0.485, 0.456, 0.406], \n",
        "                                              std=[0.229, 0.224, 0.225])\n",
        "  input_tensor = input_tensor.to(device)\n",
        "  target_layers = [model.layer4[-1]]\n",
        "  cam = EigenCAM(model=model, target_layers=target_layers, use_cuda=True)\n",
        "  targets = None if not state else [ClassifierOutputTarget(list(learn.dls.vocab).index(state))]\n",
        "  grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "  # In this example grayscale_cam has only one image in the batch:\n",
        "  grayscale_cam = grayscale_cam[0, :]\n",
        "  visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "  prediction = learn.predict(path)\n",
        "  # print(prediction[0])\n",
        "  # prediction = prediction.argmax(dim=-1)\n",
        "  # Get the model's prediction\n",
        "  # print(learn.dls.vocab[prediction])\n",
        "  # print(prediction)\n",
        "  return prediction[0], Image.fromarray(visualization)"
      ],
      "metadata": {
        "id": "Z24nJ2EVaUJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a,b = visualize('/content/e4.jpg')\n",
        "\n",
        "b"
      ],
      "metadata": {
        "id": "iP_2-e4EiC8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "state = \"Arizona\"\n",
        "for image in os.listdir(f\"/content/geolocation/{state}\")[:20]:\n",
        "  results.append(visualize(f\"/content/geolocation/{state}/{image}\", state))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "DeiqSP3QbNVG",
        "outputId": "304f0b8b-6136-451d-b8d9-33c3f353a2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-61da4dc04dfc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Arizona\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/geolocation/{state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/geolocation/{state}/{image}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_grid_image(results)"
      ],
      "metadata": {
        "id": "G6FSWZYINYd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTqqp8C9Z0mB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}